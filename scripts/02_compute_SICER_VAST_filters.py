"""
Compute VAST filters using SICER-corrected IRs generated by run_SICER_interp.py.

This script mirrors compute_GT_VAST_filters.py but loads the corrected IRs stored as
L*K x M matrices in per-(base→target) .mat files and computes:
1) Covariance matrices (R_B, R_D, r_B) for each corrected IR set
2) VAST filters for all ranks in shared_params['vast_ranks'] using joint diagonalization

Folder conventions:
- Corrected IRs are expected in:
    data_path/simulated_RIRs/SICER_corrected/{array_setup}_RT60_{rt60}/init_{base}_to_{target}.mat
- Covariances are stored under:
    covariance_path/SICER_filters/
- Filters are stored under:
    filter_files_path/SICER_VAST_filters/
"""

import os

os.environ["OMP_NUM_THREADS"] = "32"
os.environ["MKL_NUM_THREADS"] = "32"
import numpy as np
import scipy.io as sio
import sys
import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path
from dotenv import find_dotenv, dotenv_values
from datetime import datetime
import argparse
import gc

# Locate environment and shared paths/params
Loc_env = find_dotenv('.env')
CONFIG_ENV = dotenv_values(Loc_env)
if 'MainCodePath' in CONFIG_ENV:
    sys.path.append(CONFIG_ENV['MainCodePath'])

from src.utils.config_loader import load_config_module, get_shared_paths
from src.algorithms.filter_helpers import compute_covariance_matrices, diagonalize_matrices
from src.algorithms.filter_generation import fit_vast_closed_form
from src.utils.simdata import load_sicer_corrected_rirs


def get_corrected_root_dir(paths: dict, params: dict) -> Path:
    rt60 = params['rt60']
    return paths['data_path'].joinpath(
        f"simulated_RIRs/SICER_corrected/{params['array_setup']}_RT60_{rt60}"
    )


def get_sicer_covar_name(new_speed: int, old_speed: int, params: dict) -> str:
    J = params['J']
    K = params['K']
    return (
        f"{params['array_setup']}_RT60_{params['rt60']}_"
        f"init_speed_{int(old_speed):d}_interp_to_{int(new_speed):d}_J_{J}_K_{K}_SICER"
    )





def check_covariances_exist(covariance_path: Path, new_speed: int, old_speed: int, params: dict) -> bool:
    covar_name = get_sicer_covar_name(new_speed, old_speed, params)
    str_save_R_B = covariance_path.joinpath(f'R_B_{covar_name}.npz')
    str_save_R_D = covariance_path.joinpath(f'R_D_{covar_name}.npz')
    str_save_r_B = covariance_path.joinpath(f'cross_r_B_{covar_name}.npz')
    return str_save_R_B.exists() and str_save_R_D.exists() and str_save_r_B.exists()


def compute_covariance_for_pair(new_speed: int, old_speed: int,
                                paths: dict, covariance_path: Path, params: dict) -> tuple[tuple[int,int], bool]:
    """
    Compute covariances for a specific (old → new) corrected IR set.

    Returns: ((new_speed, old_speed), success)
    """
    try:
        rirs = load_sicer_corrected_rirs(paths, params, int(old_speed), int(new_speed))
        imp_resp_bz, imp_resp_dz = rirs['BZ'], rirs['DZ']

        # Compute and save covariance matrices
        covar_name = get_sicer_covar_name(new_speed, old_speed, params)
        compute_covariance_matrices(
            imp_resp_bz, imp_resp_dz,
            params['J'], params['ref_source'], params['model_delay'],
            covariance_path, covar_name, covar_name, verbose=False
        )

        return (new_speed, old_speed), True
    except Exception as e:
        print(f"Error computing covariance for {old_speed}→{new_speed}: {e}")
        import traceback
        traceback.print_exc()
        return (new_speed, old_speed), False


def compute_filters_worker(new_speed: int, old_speed: int, covariance_path: Path,
                           output_path: Path, params: dict, force_filters: bool = False) -> tuple[tuple[int,int], bool]:
    """
    Load covariances for (old→new) pair and compute VAST filters.

    Returns: ((new_speed, old_speed), success)
    """
    try:
        pid = os.getpid()

        output_path.mkdir(parents=True, exist_ok=True)
        out_name = f'SICER_VAST_filters_init_speed_{int(old_speed):d}_interp_to_{int(new_speed):d}_J_{params["J"]}.npz'
        output_file = output_path.joinpath(out_name)
        if output_file.exists() and not force_filters:
            print(f"Worker {pid}: Filters already exist for {old_speed}→{new_speed}, skipping.")
            return (new_speed, old_speed), True
        elif output_file.exists() and force_filters:
            print(f"Worker {pid}: Overwriting existing filters for {old_speed}→{new_speed}...")

        covar_name = get_sicer_covar_name(new_speed, old_speed, params)
        str_save_R_B = covariance_path.joinpath(f'R_B_{covar_name}.npz')
        str_save_R_D = covariance_path.joinpath(f'R_D_{covar_name}.npz')
        str_save_r_B = covariance_path.joinpath(f'cross_r_B_{covar_name}.npz')

        print(f"Worker {pid}: Loading covariances for {old_speed}→{new_speed}...")
        t0 = datetime.now()
        R_B = np.load(str_save_R_B)['R_B']
        R_D = np.load(str_save_R_D)['R_D']
        r_B = np.load(str_save_r_B)['r_B']
        t1 = datetime.now()
        print(f"Worker {pid}: Loaded covariances in {t1 - t0}")

        J = params['J']
        L = len(params['use_lsp'])
        mu = params['mu']
        vast_ranks = params['vast_ranks']

        print(f"Worker {pid}: Diagonalizing for {old_speed}→{new_speed}...")
        t_diag0 = datetime.now()
        eig_vec, eig_val = diagonalize_matrices(R_B, R_D, descend=True)
        del R_B, R_D
        gc.collect()
        t_diag1 = datetime.now()
        print(f"Worker {pid}: Diagonalized in {t_diag1 - t_diag0}")

        filters_array = np.zeros((len(vast_ranks), L, J))
        print(f"Worker {pid}: Computing filters for {old_speed}→{new_speed}...")
        t_f0 = datetime.now()
        for idx, rank in enumerate(vast_ranks):
            rank = int(min(int(rank), eig_vec.shape[1]))
            q_vast = fit_vast_closed_form(rank, mu, r_B, J, L, eig_vec, eig_val, mat_out=True)
            filters_array[idx] = q_vast

        np.savez_compressed(str(output_file), filters=filters_array,
                            new_speed=int(new_speed), old_speed=int(old_speed), ranks=vast_ranks)
        t_f1 = datetime.now()
        print(f"Worker {pid}: Computed and saved in {t_f1 - t_f0}")
        return (new_speed, old_speed), True

    except Exception as e:
        print(f"Error processing {old_speed}→{new_speed}: {e}")
        import traceback
        traceback.print_exc()
        return (new_speed, old_speed), False


def main():
    parser = argparse.ArgumentParser(
        description="Compute VAST filters from SICER-corrected IRs (init_base_to_target.mat)"
    )
    parser.add_argument('--config', type=Path, required=True,
                        help='Path to config module (e.g., exp1_SICER/config_RT60_0.1.py)')
    parser.add_argument('--base-speeds', type=str, default=None,
                        help="Baseline/design speeds for SICER: 'config' for shared_params, or comma list e.g. 333,343")
    parser.add_argument('--target-speeds', type=str, default='config',
                        help="Target / evaluation speeds: 'config' for shared_params, or comma list e.g. 333,343")
    parser.add_argument('--corrected-dir', type=Path, default=None,
                        help="Path to folder with corrected .mat files. Defaults to config path.")
    parser.add_argument('--parallel', action='store_true', default=False,
                        help='Enable parallel processing')
    parser.add_argument('--max-workers', type=int, default=2)
    parser.add_argument('--force-filters', action='store_true', default=False,
                        help='Force recomputation of filters even if output exists (covariances unaffected)')
    args = parser.parse_args()

    # Paths and params
    cfg = load_config_module(args.config)
    paths = get_shared_paths(config_env=CONFIG_ENV)
    params = cfg.shared_params.copy()

    corrected_dir = Path(args.corrected_dir) if args.corrected_dir is not None else get_corrected_root_dir(paths, params)
    covariance_path = paths['covariance_path'].joinpath('SICER_filters')
    output_path = paths['filter_files_path'].joinpath(f"RT60_{params['rt60']}", 'SICER_VAST_filters')
    covariance_path.mkdir(parents=True, exist_ok=True)
    output_path.mkdir(parents=True, exist_ok=True)

    # Resolve base/target speeds
    if args.base_speeds is not None:
        if args.base_speeds.lower() in ("config", "all"):
            base_speeds = params['sound_speeds'].astype(int)
        else:
            base_speeds = np.array([int(s) for s in args.base_speeds.split(',') if s.strip() != ""], dtype=int)
    else:
        # Default to single baseline: base_speed
        base_speeds = np.array([int(params['base_speed'])], dtype=int)

    if args.target_speeds == 'config':
        target_speeds = params['sound_speeds'].astype(int)
    else:
        target_speeds = np.array([int(s) for s in args.target_speeds.split(',') if s.strip() != ""], dtype=int)

    print(f"\n{'='*70}")
    print(f"Computing SICER VAST filters")
    print(f"Base speeds: {base_speeds}")
    print(f"Target speeds: {target_speeds}")
    print(f"Corrected IR dir: {corrected_dir}")
    print(f"Covariance path: {covariance_path}")
    print(f"Output path: {output_path}")
    print(f"{'='*70}\n")

    start_time = datetime.now()

    # Step 1: Check and compute covariances for all requested (old→new) pairs
    print("Step 1: Checking/Computing covariance matrices for corrected IRs...")
    missing_pairs = []
    for old in base_speeds:
        for new in target_speeds:
            if int(new) == int(old):
                # No correction needed; still allow but often unnecessary
                pass
            if not check_covariances_exist(covariance_path, int(new), int(old), params):
                missing_pairs.append((int(new), int(old)))

    if missing_pairs:
        print(f"  Need to compute covariances for {len(missing_pairs)} pairs")
        if args.parallel:
            workers = min(len(missing_pairs), args.max_workers)
            print(f"  Using {workers} workers for covariance computation")
            with ProcessPoolExecutor(max_workers=workers) as executor:
                futures = {
                    executor.submit(compute_covariance_for_pair, new, old, paths,
                                    covariance_path, params): (new, old)
                    for (new, old) in missing_pairs
                }
                for future in tqdm.tqdm(as_completed(futures), total=len(futures), desc="  Covariances"):
                    (new, old) = futures[future]
                    try:
                        (_n, _o), ok = future.result()
                        if not ok:
                            print(f"    ✗ Failed covariance for {old}→{new}")
                    except Exception as exc:
                        print(f"    ✗ Exception in covariance for {old}→{new}: {exc}")
        else:
            print("  Using sequential covariance computation")
            for (new, old) in tqdm.tqdm(missing_pairs, desc="  Covariances"):
                (_n, _o), ok = compute_covariance_for_pair(new, old, paths, covariance_path, params)
                if not ok:
                    print(f"    ✗ Failed covariance for {old}→{new}")
        print("  Covariance computation step finished")
    else:
        print("  All needed covariances already exist")

    # Step 2: Compute VAST filters
    print("\nStep 2: Computing VAST filters for all (old→new) pairs...")
    pairs = [(int(new), int(old)) for old in base_speeds for new in target_speeds]

    if args.parallel:
        workers = min(len(pairs), args.max_workers)
        print(f"  Using {workers} workers for filter computation")
        with ProcessPoolExecutor(max_workers=workers) as executor:
            futures = {
                executor.submit(compute_filters_worker, new, old, covariance_path, output_path, params, args.force_filters): (new, old)
                for (new, old) in pairs
            }
            success = 0
            fail = 0
            with tqdm.tqdm(as_completed(futures), total=len(futures), desc='  Filters') as pbar:
                for future in pbar:
                    (new, old) = futures[future]
                    try:
                        (_n, _o), ok = future.result()
                        if ok:
                            success += 1
                            print(f"    ✓ Filters computed for {old}→{new}")
                        else:
                            fail += 1
                            print(f"    ✗ Failed filters for {old}→{new}")
                    except Exception as exc:
                        fail += 1
                        print(f"    ✗ Exception for {old}→{new}: {exc}")
    else:
        print("  Using sequential filter computation")
        success = 0
        fail = 0
        for (new, old) in tqdm.tqdm(pairs, desc='  Filters'):
            (_n, _o), ok = compute_filters_worker(new, old, covariance_path, output_path, params, args.force_filters)
            if ok:
                success += 1
                print(f"    ✓ Filters computed for {old}→{new}")
            else:
                fail += 1
                print(f"    ✗ Failed filters for {old}→{new}")

    elapsed = datetime.now() - start_time
    print("\n" + "="*70)
    print(f"SICER filter computation finished in {elapsed}")
    print(f"Successfully computed filters for {success}/{len(pairs)} pairs")
    if fail:
        print(f"Failed for {fail}/{len(pairs)} pairs")
    print("="*70)


if __name__ == '__main__':
    # Keep default sequential to be safe on memory; enable with --parallel to override
    main()
